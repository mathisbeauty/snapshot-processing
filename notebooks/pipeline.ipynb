{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SingularityDAO snapshot processing pipeline\n",
    "\n",
    "This notebook it's meant to explore how the snapshots could be processed automatically.\n",
    "\n",
    "[//]: <> (The code-only version can be found at `./scripts/pipeline.py`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward parameters\n",
    "\n",
    "TOTAL_STAKING_REWARD = 550000\n",
    "\n",
    "TOTAL_REWARD = 825000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimals AGI/AGIX\n",
    "\n",
    "DECIMALS_AGI = 8\n",
    "\n",
    "CONVERT_TO_FULL_BALANCE_AGI = 10 ** DECIMALS_AGI\n",
    "\n",
    "AGI_THRESHOLD = 1000\n",
    "AGI_THRESHOLD *= CONVERT_TO_FULL_BALANCE_AGI\n",
    "\n",
    "# Decimals SDAO\n",
    "\n",
    "DECIMALS_SDAO = 18\n",
    "\n",
    "CONVERT_TO_FULL_BALANCE_SDAO = 10 ** DECIMALS_SDAO\n",
    "\n",
    "# Adjust rewards to be full balance\n",
    "\n",
    "TOTAL_STAKING_REWARD *= CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "TOTAL_REWARD *= CONVERT_TO_FULL_BALANCE_SDAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Take snapshots\n",
    "\n",
    "For the example pipeline, I'm going to use just a small number of snapshots taken manually, due to the fact that the main focus of this notebook is to create the processing pipeline, not to gather the snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import all the libraries that we're going to use for the data processing and for gathering insights about the dataset with statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Pandas for tabular data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "# from tqdm.auto import tqdm  # for notebooks\n",
    "\n",
    "tqdm.pandas(file=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is reading the `data` directory to see how many snapshots we have for each token respectively (AGI and AGIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12700788-export-tokenholders-for-contract-0x8eb24319393716668d768dcec29356ae9cffe285.csv']\n",
      "['12700800-export-tokenholders-for-contract-0x5b7533812759b45c2b44c19e320ba2cd2681b542.csv',\n",
      " '12709185-export-tokenholders-for-contract-0x5b7533812759b45c2b44c19e320ba2cd2681b542.csv',\n",
      " '12709949-export-tokenholders-for-contract-0x5b7533812759b45c2b44c19e320ba2cd2681b542.csv']\n"
     ]
    }
   ],
   "source": [
    "def get_snapshots(path):\n",
    "    return next(walk(path), (None, None, []))[2]\n",
    "\n",
    "agi_snapshots_files = get_snapshots('../data/holders/agi')\n",
    "agix_snapshots_files = get_snapshots('../data/holders/agix')\n",
    "\n",
    "pprint(agi_snapshots_files)\n",
    "pprint(agix_snapshots_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load snapshots for liquidity providers and stakers.\n",
    "\n",
    "In this example, the snapshots are the same as the AGIX holders, with some accounts removed manually in the first snapshot, to focus on developing the calculations first, leaving getting the data from the database or CSV files for later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_snapshots_files = get_snapshots('../data/lp')\n",
    "\n",
    "stakers_snapshots_files = get_snapshots('../data/stakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the snapshots' contents using `pandas` and convert balances to unsinged long numbers (SDAO wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(folder, file):\n",
    "    # Read csv file\n",
    "    data_frame = pd.read_csv('../data/%s/%s' % (folder, file))\n",
    "    # Sort accounts by holding amount, larger holders at the top\n",
    "    data_frame = data_frame.astype({'Balance': int })\n",
    "    data_frame['Balance'] = data_frame['Balance'].apply(lambda x: int(x * CONVERT_TO_FULL_BALANCE_AGI))\n",
    "    data_frame = data_frame.sort_values('Balance', ascending=False)\n",
    "    return data_frame\n",
    "\n",
    "agi_snapshots_raw = [read_csv(\"holders\", \"agi/\" + file) for file in agi_snapshots_files]\n",
    "agix_snapshots_raw = [read_csv(\"holders\", \"agix/\" + file) for file in agix_snapshots_files]\n",
    "\n",
    "lp_snapshots_raw = [read_csv(\"lp\", file) for file in lp_snapshots_files]\n",
    "stakers_snapshots_raw = [read_csv(\"stakers\", file) for file in stakers_snapshots_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snapshots are now loaded as a panda DataFrame.\n",
    "\n",
    "Let's see the structure of a single snapshot and a single row, to get a better idea of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HolderAddress', 'Balance', 'PendingBalanceUpdate'], dtype='object')\n",
      "HolderAddress           0xbe0eb53f46cd790cd13851d5eff43d12404d33e8\n",
      "Balance                                          14182336000000000\n",
      "PendingBalanceUpdate                                            No\n",
      "Name: 7738, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(agi_snapshots_raw[0].columns)\n",
    "print(agi_snapshots_raw[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the `PendingBalanceUpdate` column and rename the other two, to clean the dataset and make it more practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['address', 'balance'], dtype='object')\n",
      "address    0xbe0eb53f46cd790cd13851d5eff43d12404d33e8\n",
      "balance                             14182336000000000\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clear_snapshot(snapshot):\n",
    "    cleaned_snapshot = snapshot.drop('PendingBalanceUpdate', axis=\"columns\")\n",
    "    cleaned_snapshot = cleaned_snapshot.rename(columns={\"HolderAddress\": \"address\", \"Balance\": \"balance\"})\n",
    "    cleaned_snapshot = cleaned_snapshot.reset_index(drop=True)\n",
    "    return cleaned_snapshot\n",
    "\n",
    "agi_snapshots = [clear_snapshot(snapshot) for snapshot in agi_snapshots_raw]\n",
    "agix_snapshots = [clear_snapshot(snapshot) for snapshot in agix_snapshots_raw]\n",
    "\n",
    "lp_snapshots = [clear_snapshot(snapshot) for snapshot in lp_snapshots_raw]\n",
    "stakers_snapshots = [clear_snapshot(snapshot) for snapshot in stakers_snapshots_raw]\n",
    "\n",
    "print(agi_snapshots[0].columns)\n",
    "# Address and balance from the account with the largest holding, one of the Binance wallets\n",
    "print(agi_snapshots[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate eligibility\n",
    "\n",
    "With the snapshot data ready, we can start to calculate the eligible addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portal Registration\n",
    "\n",
    "At this point, the snapshots can be filtered by the set of addresses that have registered in the airdrop portal for a given month.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial snapshot\n",
    "\n",
    "There's an initial snapshot that delimits how many addresses are eligible for the airdrop.\n",
    "\n",
    "In my case it's the snapshot of the frozen AGI balances, but in the airdrop it would be the snapshot from 17th of April 2021, at 23:59 UTC+0.\n",
    "\n",
    "Let's create a subset based on the addresses from the first snapshot that have more than 1.000 AGI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGI Snapshots: 1\n",
      "AGIX Snapshots: 3\n",
      "LP Snapshots: 3\n",
      "Stakers Snapshots: 3\n",
      "\n",
      "Total Addresses (holders): 25247\n",
      "Eligible Addresses (holders): 16368\n",
      "\n",
      "Total Addresses (LP): 189\n",
      "Eligible Addresses (LP): 111\n",
      "\n",
      "Total Addresses (stakers): 1405\n",
      "Eligible Addresses (stakers): 946\n",
      "\n",
      "\n",
      "address    0x4c4ca064972ff8ff64568319c92367c159c52238\n",
      "balance                                  100000000000\n",
      "Name: 16367, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"AGI Snapshots: %s\" % len(agi_snapshots))\n",
    "print(\"AGIX Snapshots: %s\" % len(agix_snapshots))\n",
    "print(\"LP Snapshots: %s\" % len(lp_snapshots))\n",
    "print(\"Stakers Snapshots: %s\" % len(stakers_snapshots))\n",
    "print()\n",
    "\n",
    "# Get the first snapshot and use it as the starting point for the calculations\n",
    "def get_initial(initial_snapshot, category):\n",
    "    total_addresses = len(initial_snapshot.index)\n",
    "    eligible_addresses_initial = initial_snapshot[initial_snapshot['balance'] >= AGI_THRESHOLD]\n",
    "    \n",
    "    print('Total Addresses (%s): %s' % (category, total_addresses))\n",
    "    print('Eligible Addresses (%s): %s' % (category, len(eligible_addresses_initial.index)))\n",
    "    print()\n",
    "    \n",
    "    return eligible_addresses_initial\n",
    "\n",
    "eligible_addresses_holders = get_initial(agi_snapshots[0], 'holders')\n",
    "eligible_addresses_lp = get_initial(lp_snapshots[0], 'LP')\n",
    "eligible_addresses_stakers = get_initial(stakers_snapshots[0], 'stakers')\n",
    "\n",
    "print()\n",
    "# Print address with smaller eligible balance\n",
    "print(eligible_addresses_holders.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from the initial ~26k addresses, only 16689 pass the threshold to be eligible.\n",
    "\n",
    "Now, it's a matter of iterating through the remaining snapshots using this initial set of accounts, and checking if the accounts are still eligible, removing the ones that are below the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the snapshots\n",
    "\n",
    "First, let's merge all snapshots (AGI and AGIX) into a single array and discard the first one, as that one it's already processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge snapshots\n",
    "holders_snapshots = agi_snapshots + agix_snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we iterate over the snapshots, filtering the initial set of eligible accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Eligible Addresses (holders): 16368\n",
      "\n",
      "Snapshot #0\n",
      "Eligible Addresses from snapshot: 16368 addresses\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16368/16368 [00:22<00:00, 716.67it/s]\n",
      "Eligible Addresses: 16368\n",
      "\n",
      "Snapshot #1\n",
      "Eligible Addresses from snapshot: 16470 addresses\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15421/15421 [00:21<00:00, 728.50it/s]\n",
      "Eligible Addresses: 15421\n",
      "\n",
      "Snapshot #2\n",
      "Eligible Addresses from snapshot: 16470 addresses\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15402/15402 [00:21<00:00, 729.56it/s]\n",
      "Eligible Addresses: 15402\n",
      "\n",
      "Snapshot #3\n",
      "Eligible Addresses from snapshot: 16473 addresses\n",
      " 38%|█████████████████████████████████████████████████████████████▎                                                                                                    | 5826/15400 [00:07<00:13, 727.06it/s]"
     ]
    }
   ],
   "source": [
    "def filter_addresses(initial_df, snapshot_df):\n",
    "    # Calculate intersection of eligible addresses between existing set and snapshot set\n",
    "    initial_set = set(initial_df['address'])\n",
    "    snapshot_set = set(snapshot_df['address'])\n",
    "    addresses_intersection = list(initial_set.intersection(snapshot_set))\n",
    "    \n",
    "    # Filter addresses based on whether they're contained on the intersection set or not\n",
    "    filtered_df = initial_df[initial_df.apply(lambda x: x['address'] in addresses_intersection, axis=1)].copy()\n",
    "    \n",
    "    def filter_lowest_balance(x):\n",
    "        return np.amin([x['balance'], snapshot_df.loc[snapshot_df['address'] == x['address']].iloc[0]['balance']])\n",
    "    \n",
    "    # Set balance amount to the lowest of the two values (initial value and snapshot value),\n",
    "    # to only take into account the lower balance\n",
    "    filtered_df['balance'] = filtered_df.copy().progress_apply(filter_lowest_balance, axis=1)\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def get_eligible(initial_df, snapshots, category):\n",
    "    print()\n",
    "    print('Initial Eligible Addresses (%s): %s' % (category, len(initial_df.index)))\n",
    "    print()\n",
    "\n",
    "    eligible_df = initial_df\n",
    "\n",
    "    for index, snapshot in enumerate(snapshots):\n",
    "        print('Snapshot #%s' % index)\n",
    "        snapshot_eligible = snapshot[snapshot['balance'] >= AGI_THRESHOLD]\n",
    "        print('Eligible Addresses from snapshot: %s addresses' % len(snapshot_eligible.index))\n",
    "        eligible_df = filter_addresses(eligible_df, snapshot_eligible)\n",
    "        print('Eligible Addresses: %s' % len(eligible_df.index))\n",
    "        print()\n",
    "\n",
    "    print('Total Eligible Addresses (%s): %s' % (category, len(eligible_df.index)))\n",
    "    \n",
    "    return eligible_df\n",
    "    \n",
    "\n",
    "eligible_addresses_holders = get_eligible(eligible_addresses_holders, holders_snapshots, 'holders')\n",
    "eligible_addresses_lp = get_eligible(eligible_addresses_lp, lp_snapshots, 'LP')\n",
    "eligible_addresses_stakers = get_eligible(eligible_addresses_stakers, stakers_snapshots, 'stakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculating airdrop rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge address lists\n",
    "\n",
    "A single address could have multiple rewards. To account for this, we'll merge all the eligible addresses into a single list, removing duplicates, and add an extra column for each kind of reward.\n",
    "\n",
    "That way, we'll be able to show all the reward types in the airdrop portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = {\n",
    "    \"holder\": eligible_addresses_holders,\n",
    "    \"lp\": eligible_addresses_lp,\n",
    "    \"staker\": eligible_addresses_stakers\n",
    "}\n",
    "\n",
    "# Merge all eligible addresses\n",
    "\n",
    "addresses_df = pd.concat(list(datasets_dict.values())).drop_duplicates('address').drop('balance', axis=1)\n",
    "addresses_df = addresses_df.reset_index(drop=True)\n",
    "\n",
    "print('Total addresses participating in the airdrop: %s' % len(addresses_df.index))\n",
    "\n",
    "# Append rewards to the provided column, matching addresses between both sets\n",
    "def append_column_by_address(addresses_df, rewards_df, column, new_column_name=None):\n",
    "    def get_row_value_by_address(address):\n",
    "        matching_rows = rewards_df.loc[rewards_df['address'] == address]\n",
    "        total_matching_rows = len(matching_rows)\n",
    "        if total_matching_rows == 1:\n",
    "            return matching_rows.iloc[0][column]\n",
    "        elif total_matching_rows == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            raise Exception('Error appending column to final file', 'addresses are duplicated')\n",
    "    \n",
    "    result_df = addresses_df.copy()\n",
    "    if new_column_name is None:\n",
    "        new_column_name = column\n",
    "    print()\n",
    "    print('Appending \"%s\" column to final file' % new_column_name)\n",
    "    result_df.insert(len(result_df.columns), new_column_name, addresses_df.progress_apply(lambda x: get_row_value_by_address(x['address']), axis=1).astype(np.longdouble))\n",
    "    print()\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stakers\n",
    "\n",
    "There are two kinds of rewards for stakers:\n",
    "- Per user (divided equally among staking wallets)\n",
    "- Per stake amount (delivered proportionally to the amounts staked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Eligible Stakers: %s' % len(eligible_addresses_stakers.index))\n",
    "\n",
    "rewards_stakers_df = eligible_addresses_stakers.copy()\n",
    "\n",
    "# Rewards per user\n",
    "\n",
    "half_staking_reward = TOTAL_STAKING_REWARD / 2\n",
    "\n",
    "reward_per_user = half_staking_reward / len(eligible_addresses_stakers)\n",
    "\n",
    "adjusted_reward_per_user = reward_per_user / CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "print('Staking reward per user: %s' % adjusted_reward_per_user)\n",
    "\n",
    "rewards_stakers_df.insert(len(rewards_stakers_df.columns), 'staker_reward_per_user', adjusted_reward_per_user)\n",
    "\n",
    "# Rewards per stake\n",
    "\n",
    "total_stake = eligible_addresses_stakers['balance'].sum()\n",
    "\n",
    "rewards_stakers_df['staker_reward_per_stake'] = rewards_stakers_df.apply(lambda x: half_staking_reward * np.double(x['balance']) / np.double(total_stake) / CONVERT_TO_FULL_BALANCE_SDAO, axis=1)\n",
    "\n",
    "display(rewards_stakers_df)\n",
    "\n",
    "adjusted_half_staker_reward = (half_staking_reward / CONVERT_TO_FULL_BALANCE_SDAO)\n",
    "\n",
    "calculated_staker_reward_per_user = np.sum(list(rewards_stakers_df['staker_reward_per_user']))\n",
    "\n",
    "calculated_staker_reward_per_stake = np.sum(list(rewards_stakers_df['staker_reward_per_stake']))\n",
    "\n",
    "print()\n",
    "print('Allocated reward (stakers, per user): %s' % adjusted_half_staker_reward)\n",
    "print('Calculated reward (stakers, per user): %s' % calculated_staker_reward_per_user)\n",
    "print()\n",
    "print('Allocated reward (stakers, per stake): %s' % adjusted_half_staker_reward)\n",
    "print('Calculated reward (stakers, per stake): %s' % calculated_staker_reward_per_stake)\n",
    "print()\n",
    "print('Allocated reward (stakers, total): %s' % (TOTAL_STAKING_REWARD / CONVERT_TO_FULL_BALANCE_SDAO))\n",
    "print('Calculated reward (stakers, total): %s' % (calculated_staker_reward_per_user + calculated_staker_reward_per_stake))\n",
    "print()\n",
    "\n",
    "per_user_error = calculated_staker_reward_per_user != adjusted_half_staker_reward\n",
    "\n",
    "per_stake_error = calculated_staker_reward_per_stake != adjusted_half_staker_reward\n",
    "\n",
    "total_error = (calculated_staker_reward_per_user + calculated_staker_reward_per_stake) != (adjusted_half_staker_reward * 2)\n",
    "\n",
    "if per_user_error or per_stake_error or total_error:\n",
    "    raise Exception('Error calculating rewards (stakers)', 'final reward sum does not match allocated reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the calculated rewards to final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rewards_stakers_df['balance'] /= CONVERT_TO_FULL_BALANCE_AGI\n",
    "\n",
    "addresses_df = append_column_by_address(addresses_df, rewards_stakers_df, 'staker_reward_per_user')\n",
    "addresses_df = append_column_by_address(addresses_df, rewards_stakers_df, 'staker_reward_per_stake')\n",
    "addresses_df['staker_reward'] = addresses_df['staker_reward_per_user'] + addresses_df['staker_reward_per_stake']\n",
    "addresses_df = append_column_by_address(addresses_df, rewards_stakers_df, 'balance', 'used_staker_balance')\n",
    "\n",
    "display(addresses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holders and LP\n",
    "\n",
    "Knowing the eligibility of the addresses, we can calculate the rewards for each user using the following formula.\n",
    "\n",
    "`Reward = total_reward * log10(1+user_balance) / SUM(log10(1+user_balance))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SUM(log10(1+user_balance)) as a constant variable\n",
    "\n",
    "holder_balances = list(eligible_addresses_holders['balance'])\n",
    "\n",
    "lp_balances = list(eligible_addresses_lp['balance'])\n",
    "\n",
    "balances_log10 = [np.log10(1 + (balance)) for balance in (holder_balances + lp_balances)]\n",
    "\n",
    "sum_balances_log10 = np.sum(balances_log10)\n",
    "\n",
    "# Define the function that calculates the reward for each user\n",
    "\n",
    "def calculate_reward(total_reward, user_balance_index):\n",
    "    user_balance_log10 = balances_log10[user_balance_index]\n",
    "    reward_percentage = np.longdouble(user_balance_log10) / np.longdouble(sum_balances_log10)\n",
    "    # Calculate reward and convert to final balance\n",
    "    return (total_reward * user_balance_log10 / sum_balances_log10) / CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "# Calculate rewards and add the SDAO value as a column to the DateFrame\n",
    "\n",
    "holder_rewards = [calculate_reward(TOTAL_REWARD, index) for index, balance in enumerate(holder_balances)]\n",
    "\n",
    "lp_rewards = [calculate_reward(TOTAL_REWARD, len(holder_balances) + index) for index, balance in enumerate(lp_balances)]\n",
    "\n",
    "holder_rewards_df = eligible_addresses_holders.copy()\n",
    "\n",
    "lp_rewards_df = eligible_addresses_lp.copy()\n",
    "\n",
    "holder_rewards_df.insert(0, 'reward', holder_rewards)\n",
    "\n",
    "holder_rewards_df['balance'] /= CONVERT_TO_FULL_BALANCE_AGI\n",
    "\n",
    "lp_rewards_df.insert(0, 'reward', lp_rewards)\n",
    "\n",
    "lp_rewards_df['balance'] /= CONVERT_TO_FULL_BALANCE_AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verify rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the total amount of allocated reward matches the expected value\n",
    "\n",
    "calculated_reward = np.sum(list(holder_rewards_df['reward'])) + np.sum(list(lp_rewards_df['reward']))\n",
    "\n",
    "adjusted_total_reward = (TOTAL_REWARD / CONVERT_TO_FULL_BALANCE_SDAO)\n",
    "\n",
    "print('Allocated reward (holders and LP): %s' % adjusted_total_reward)\n",
    "print('Calculated reward (holders and LP): %s' % calculated_reward)\n",
    "\n",
    "if calculated_reward != adjusted_total_reward:\n",
    "    raise Exception('Error calculating rewards', 'final reward sum does not match allocated reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the calculated rewards to final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rewards to final data frame\n",
    "\n",
    "addresses_df = append_column_by_address(addresses_df, holder_rewards_df, 'reward', 'holder_reward')\n",
    "addresses_df = append_column_by_address(addresses_df, holder_rewards_df, 'balance', 'used_holder_balance')\n",
    "addresses_df = append_column_by_address(addresses_df, lp_rewards_df, 'reward', 'lp_reward')\n",
    "addresses_df = append_column_by_address(addresses_df, lp_rewards_df, 'balance', 'used_lp_balance')\n",
    "addresses_df['total_reward'] = addresses_df['staker_reward_per_user'] + addresses_df['staker_reward_per_stake'] + addresses_df['holder_reward'] + addresses_df['lp_reward']\n",
    "\n",
    "total_calculated_reward = (addresses_df['total_reward'] * CONVERT_TO_FULL_BALANCE_SDAO).sum()\n",
    "\n",
    "if total_calculated_reward != float(TOTAL_REWARD + TOTAL_STAKING_REWARD):\n",
    "    print('Total rounding error: %s SDAO' % '{:.18f}'.format((TOTAL_REWARD + TOTAL_STAKING_REWARD) - (addresses_df['total_reward'] * CONVERT_TO_FULL_BALANCE_SDAO).sum()))\n",
    "    raise Exception('Error calculating rewards', 'final reward sum does not match allocated reward')\n",
    "\n",
    "total_calculated_reward /= CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "# Sort addresses by total reward (descending) and recalculate indexes\n",
    "\n",
    "addresses_df = addresses_df.sort_values('total_reward', ascending=False)\n",
    "addresses_df = addresses_df.reset_index(drop=True)\n",
    "\n",
    "print()\n",
    "print('Allocated reward (stakers, holders and LP): %s' % (float(TOTAL_REWARD + TOTAL_STAKING_REWARD) / CONVERT_TO_FULL_BALANCE_SDAO))\n",
    "print('Calculated reward (stakers, holders and LP): %s' % total_calculated_reward)\n",
    "print()\n",
    "\n",
    "print()\n",
    "print('Final rewards')\n",
    "display(addresses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding unclaimed balances\n",
    "\n",
    "The missing step would be to sum all the unclaimed amounts from previous airdrops, for this example that's not possible with the data at hand though."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e11c16bd8665eb0b93b5a4e36de9de775b152bd48248748b339502fe1d55318"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
