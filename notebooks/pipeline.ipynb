{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SingularityDAO snapshot processing pipeline\n",
    "\n",
    "This notebook it's meant to explore how the snapshots could be processed automatically.\n",
    "\n",
    "[//]: <> (The code-only version can be found at `./scripts/pipeline.py`.)\n",
    "\n",
    "## Notes\n",
    "\n",
    "### Manually getting the data\n",
    "\n",
    "Due to the fact that AGIX has less than 100,000 holders, we can manually download a .csv file with the balances of all holders [using Etherscan](https://etherscan.io/exportData?type=tokenholders&contract=0x5b7533812759b45c2b44c19e320ba2cd2681b542&decimal=8).\n",
    "\n",
    "This is doable due to the small number of holders, but not really practical for automating the production pipeline. As this is just an example, it will work for our purposes here.\n",
    "\n",
    "### Scalability\n",
    "\n",
    "The main purpose of this notebook it's to explore how to automate the data processing of the snapshots.\n",
    "\n",
    "That's the reason why we are only dealing with a subset of the snapshots.\n",
    "\n",
    "Once the process works reliably and can be performed automatically, the next step would be to containerize it for cloud processing.\n",
    "\n",
    "In principle, the processing could be distributed by grouping all the addresses to process in batches of N addresses, and each container would calculate the eligibility for one batch at a time. Once the batch it's processed, the container would either request another one, or be destroyed if there aren't more.\n",
    "\n",
    "This shouldn't be necessary if the amount of the data it's relatively small and the calculations can be done in a single machine quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Take snapshots\n",
    "\n",
    "For the example pipeline, I'm going to use just a small number of snapshots taken manually, due to the fact that the main focus of this notebook is to create the processing pipeline, not to gather the snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to import all the libraries that we're going to use for the data processing and for gathering insights about the dataset with statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# Pandas for tabular data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "# from tqdm.auto import tqdm  # for notebooks\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is reading the `data` directory to see how many snapshots we have for each token respectively (AGI and AGIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12700788-export-tokenholders-for-contract-0x8eb24319393716668d768dcec29356ae9cffe285.csv']\n",
      "['12700800-export-tokenholders-for-contract-0x5b7533812759b45c2b44c19e320ba2cd2681b542.csv',\n",
      " '12709185-export-tokenholders-for-contract-0x5b7533812759b45c2b44c19e320ba2cd2681b542.csv',\n",
      " '12709949-export-tokenholders-for-contract-0x5b7533812759b45c2b44c19e320ba2cd2681b542.csv']\n"
     ]
    }
   ],
   "source": [
    "def get_snapshots(path):\n",
    "    return next(walk(path), (None, None, []))[2]\n",
    "\n",
    "agi_snapshots_files = get_snapshots('../data/holders/agi')\n",
    "agix_snapshots_files = get_snapshots('../data/holders/agix')\n",
    "\n",
    "pprint(agi_snapshots_files)\n",
    "pprint(agix_snapshots_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load snapshots for liquidity providers and stakers.\n",
    "\n",
    "In this example, the snapshots are the same as the AGIX holders, to focus on developing the calculations first, leaving getting the data from the database for later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_snapshots_files = get_snapshots('../data/lp')\n",
    "\n",
    "stakers_snapshots_files = get_snapshots('../data/stakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the snapshots' contents using `pandas` and convert balances to unsinged long numbers (SDAO wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimals AGI/AGIX\n",
    "\n",
    "DECIMALS_AGI = 8\n",
    "\n",
    "CONVERT_TO_FULL_BALANCE_AGI = np.power(np.ulonglong(10), DECIMALS_AGI)\n",
    "\n",
    "AGI_THRESHOLD = 1000 * CONVERT_TO_FULL_BALANCE_AGI\n",
    "\n",
    "def read_csv(folder, file):\n",
    "    # Read csv file\n",
    "    data_frame = pd.read_csv('../data/%s/%s' % (folder, file))\n",
    "    # Sort accounts by holding amount, larger holders at the top\n",
    "    data_frame = data_frame.astype({'Balance': np.ulonglong})\n",
    "    data_frame['Balance'] = data_frame['Balance'].apply(lambda x: x * CONVERT_TO_FULL_BALANCE_AGI)\n",
    "    data_frame = data_frame.sort_values('Balance', ascending=False)\n",
    "    return data_frame\n",
    "\n",
    "agi_snapshots_raw = [read_csv(\"holders\", \"agi/\" + file) for file in agi_snapshots_files]\n",
    "agix_snapshots_raw = [read_csv(\"holders\", \"agix/\" + file) for file in agix_snapshots_files]\n",
    "\n",
    "lp_snapshots_raw = [read_csv(\"lp\", file) for file in lp_snapshots_files]\n",
    "stakers_snapshots_raw = [read_csv(\"stakers\", file) for file in stakers_snapshots_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The snapshots are now loaded as a panda DataFrame.\n",
    "\n",
    "Let's see the structure of a single snapshot and a single row, to get a better idea of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HolderAddress', 'Balance', 'PendingBalanceUpdate'], dtype='object')\n",
      "HolderAddress           0xbe0eb53f46cd790cd13851d5eff43d12404d33e8\n",
      "Balance                                        14182336000000000.0\n",
      "PendingBalanceUpdate                                            No\n",
      "Name: 7738, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(agi_snapshots_raw[0].columns)\n",
    "print(agi_snapshots_raw[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the `PendingBalanceUpdate` column and rename the other two, to clean the dataset and make it more practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['address', 'balance'], dtype='object')\n",
      "address    0xbe0eb53f46cd790cd13851d5eff43d12404d33e8\n",
      "balance                           14182336000000000.0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clear_snapshot(snapshot):\n",
    "    cleaned_snapshot = snapshot.drop('PendingBalanceUpdate', axis=\"columns\")\n",
    "    cleaned_snapshot = cleaned_snapshot.rename(columns={\"HolderAddress\": \"address\", \"Balance\": \"balance\"})\n",
    "    cleaned_snapshot = cleaned_snapshot.reset_index(drop=True)\n",
    "    return cleaned_snapshot\n",
    "\n",
    "agi_snapshots = [clear_snapshot(snapshot) for snapshot in agi_snapshots_raw]\n",
    "agix_snapshots = [clear_snapshot(snapshot) for snapshot in agix_snapshots_raw]\n",
    "\n",
    "lp_snapshots = [clear_snapshot(snapshot) for snapshot in lp_snapshots_raw]\n",
    "stakers_snapshots = [clear_snapshot(snapshot) for snapshot in stakers_snapshots_raw]\n",
    "\n",
    "print(agi_snapshots[0].columns)\n",
    "# Address and balance from the account with the largest holding, one of the Binance wallets\n",
    "print(agi_snapshots[0].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate eligibility\n",
    "\n",
    "With the snapshot data ready, we can start to calculate the eligible addresses.\n",
    "\n",
    "Note that the following is intended to illustrate the process, but with the actual dataset of snapshots, a similar but more complex processing would be applied.\n",
    "\n",
    "Additionally, for the sake of the example, this process will only take into account holders, ignoring stakers and liquidity providers.\n",
    "\n",
    "Nonetheless, it's feasible to adapt this same series of steps to stakers and liquidity providers, by preparing their respective datasets as described in step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial snapshot\n",
    "\n",
    "There's an initial snapshot that delimits how many addresses are eligible for the airdrop.\n",
    "\n",
    "In my case it's the snapshot of the frozen AGI balances, but in the airdrop it would be the snapshot from 17th of April 2021, at 23:59 UTC+0.\n",
    "\n",
    "Let's create a subset based on the addresses from the first snapshot that have more than 1.000 AGI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGI Snapshots: 1\n",
      "AGIX Snapshots: 3\n",
      "LP Snapshots: 3\n",
      "Stakers Snapshots: 3\n",
      "\n",
      "Total Addresses (holders): 25247\n",
      "Eligible Addresses (holders): 16368\n",
      "\n",
      "Total Addresses (LP): 189\n",
      "Eligible Addresses (LP): 111\n",
      "\n",
      "Total Addresses (stakers): 1405\n",
      "Eligible Addresses (stakers): 946\n",
      "\n",
      "\n",
      "address    0x4c4ca064972ff8ff64568319c92367c159c52238\n",
      "balance                                100000000000.0\n",
      "Name: 16367, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"AGI Snapshots: %s\" % len(agi_snapshots))\n",
    "print(\"AGIX Snapshots: %s\" % len(agix_snapshots))\n",
    "print(\"LP Snapshots: %s\" % len(lp_snapshots))\n",
    "print(\"Stakers Snapshots: %s\" % len(stakers_snapshots))\n",
    "print()\n",
    "\n",
    "# Get the first snapshot and use it as the starting point for the calculations\n",
    "def get_initial(initial_snapshot, category):\n",
    "    total_addresses = len(initial_snapshot.index)\n",
    "    eligible_addresses_initial = initial_snapshot[initial_snapshot['balance'] >= AGI_THRESHOLD]\n",
    "    \n",
    "    print('Total Addresses (%s): %s' % (category, total_addresses))\n",
    "    print('Eligible Addresses (%s): %s' % (category, len(eligible_addresses_initial.index)))\n",
    "    print()\n",
    "    \n",
    "    return eligible_addresses_initial\n",
    "\n",
    "eligible_addresses_holders = get_initial(agi_snapshots[0], 'holders')\n",
    "eligible_addresses_lp = get_initial(lp_snapshots[0], 'LP')\n",
    "eligible_addresses_stakers = get_initial(stakers_snapshots[0], 'stakers')\n",
    "\n",
    "print()\n",
    "# Print address with smaller eligible balance\n",
    "print(eligible_addresses_holders.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from the initial ~26k addresses, only 16689 pass the threshold to be eligible.\n",
    "\n",
    "Now, it's a matter of iterating through the remaining snapshots using this initial set of accounts, and checking if the accounts are still eligible, removing the ones that are below the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the snapshots\n",
    "\n",
    "First, let's merge all snapshots (AGI and AGIX) into a single array and discard the first one, as that one it's already processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge snapshots\n",
    "holders_snapshots = agi_snapshots + agix_snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we iterate over the snapshots, filtering the initial set of eligible accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Eligible Addresses (holders): 16368\n",
      "\n",
      "Snapshot #0\n",
      "Eligible Addresses from snapshot: 16368 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16368/16368 [00:22<00:00, 713.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 16368\n",
      "\n",
      "Snapshot #1\n",
      "Eligible Addresses from snapshot: 16470 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15421/15421 [00:21<00:00, 711.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 15421\n",
      "\n",
      "Snapshot #2\n",
      "Eligible Addresses from snapshot: 16470 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15402/15402 [00:21<00:00, 722.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 15402\n",
      "\n",
      "Snapshot #3\n",
      "Eligible Addresses from snapshot: 16473 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15400/15400 [00:21<00:00, 723.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 111/111 [00:00<00:00, 2265.40it/s]\n",
      " 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 74/109 [00:00<00:00, 740.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 15400\n",
      "\n",
      "Total Eligible Addresses (holders): 15400\n",
      "\n",
      "Initial Eligible Addresses (LP): 111\n",
      "\n",
      "Snapshot #0\n",
      "Eligible Addresses from snapshot: 111 addresses\n",
      "Eligible Addresses: 111\n",
      "\n",
      "Snapshot #1\n",
      "Eligible Addresses from snapshot: 16470 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 109/109 [00:00<00:00, 717.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 109/109 [00:00<00:00, 731.54it/s]\n",
      "  0%|                                                                                                                                                                                | 0/946 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 109\n",
      "\n",
      "Snapshot #2\n",
      "Eligible Addresses from snapshot: 16473 addresses\n",
      "Eligible Addresses: 109\n",
      "\n",
      "Total Eligible Addresses (LP): 109\n",
      "\n",
      "Initial Eligible Addresses (stakers): 946\n",
      "\n",
      "Snapshot #0\n",
      "Eligible Addresses from snapshot: 946 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:00<00:00, 2047.56it/s]\n",
      "  8%|████████████▉                                                                                                                                                         | 74/946 [00:00<00:01, 732.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 946\n",
      "\n",
      "Snapshot #1\n",
      "Eligible Addresses from snapshot: 16470 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:01<00:00, 727.69it/s]\n",
      " 16%|██████████████████████████▏                                                                                                                                          | 150/945 [00:00<00:01, 745.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 946\n",
      "\n",
      "Snapshot #2\n",
      "Eligible Addresses from snapshot: 16473 addresses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 945/945 [00:01<00:00, 731.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible Addresses: 945\n",
      "\n",
      "Total Eligible Addresses (stakers): 945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_addresses(initial_df, snapshot_df):\n",
    "    # Calculate intersection of eligible addresses between existing set and snapshot set\n",
    "    initial_set = set(initial_df['address'])\n",
    "    snapshot_set = set(snapshot_df['address'])\n",
    "    addresses_intersection = list(initial_set.intersection(snapshot_set))\n",
    "    \n",
    "    # Filter addresses based on whether they're contained on the intersection set or not\n",
    "    filtered_df = initial_df[initial_df.apply(lambda x: x['address'] in addresses_intersection, axis=1)].copy()\n",
    "    \n",
    "    def filter_lowest_balance(x):\n",
    "        return np.amin([x['balance'], snapshot_df.loc[snapshot_df['address'] == x['address']].iloc[0]['balance']])\n",
    "    \n",
    "    # Set balance amount to the lowest of the two values (initial value and snapshot value),\n",
    "    # to only take into account the lower balance\n",
    "    filtered_df['balance'] = filtered_df.copy().progress_apply(filter_lowest_balance, axis=1)\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def get_eligible(initial_df, snapshots, category):\n",
    "    print()\n",
    "    print('Initial Eligible Addresses (%s): %s' % (category, len(initial_df.index)))\n",
    "    print()\n",
    "\n",
    "    eligible_df = initial_df\n",
    "\n",
    "    for index, snapshot in enumerate(snapshots):\n",
    "        print('Snapshot #%s' % index)\n",
    "        snapshot_eligible = snapshot[snapshot['balance'] >= AGI_THRESHOLD]\n",
    "        print('Eligible Addresses from snapshot: %s addresses' % len(snapshot_eligible.index))\n",
    "        eligible_df = filter_addresses(eligible_df, snapshot_eligible)\n",
    "        print('Eligible Addresses: %s' % len(eligible_df.index))\n",
    "        print()\n",
    "\n",
    "    print('Total Eligible Addresses (%s): %s' % (category, len(eligible_df.index)))\n",
    "    \n",
    "    return eligible_df\n",
    "    \n",
    "\n",
    "eligible_addresses_holders = get_eligible(eligible_addresses_holders, holders_snapshots, 'holders')\n",
    "eligible_addresses_lp = get_eligible(eligible_addresses_lp, lp_snapshots, 'LP')\n",
    "eligible_addresses_stakers = get_eligible(eligible_addresses_stakers, stakers_snapshots, 'stakers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating airdrop amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimals SDAO\n",
    "\n",
    "DECIMALS_SDAO = 18\n",
    "\n",
    "CONVERT_TO_FULL_BALANCE_SDAO = np.power(np.ulonglong(10), DECIMALS_SDAO)\n",
    "\n",
    "# Reward parameters\n",
    "\n",
    "TOTAL_STAKING_REWARD = 550000.0\n",
    "\n",
    "TOTAL_REWARD = 825000.0\n",
    "\n",
    "# Adjust rewards to be full balance\n",
    "\n",
    "TOTAL_STAKING_REWARD *= CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "TOTAL_REWARD *= CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "def calculate_percentage(total, percentage, decimals):\n",
    "    # Move the position of the floating point to have more precision around small percentages\n",
    "    return (total * (percentage * np.power(10, decimals)) / np.power(10, decimals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge address lists\n",
    "\n",
    "A single address could have multiple rewards. To account for this, we'll merge all the eligible addresses into a single list, removing duplicates, and add an extra column for each kind of reward.\n",
    "\n",
    "That way, we'll be able to show all the reward types in the airdrop portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total addresses participating in the airdrop: 15466\n"
     ]
    }
   ],
   "source": [
    "datasets_dict = {\n",
    "    \"holder\": eligible_addresses_holders,\n",
    "    \"lp\": eligible_addresses_lp,\n",
    "    \"staker\": eligible_addresses_stakers\n",
    "}\n",
    "\n",
    "# Merge all eligible addresses\n",
    "\n",
    "addresses_df = pd.concat(list(datasets_dict.values())).drop_duplicates('address').drop('balance', axis=1)\n",
    "addresses_df = addresses_df.reset_index(drop=True)\n",
    "\n",
    "print('Total addresses participating in the airdrop: %s' % len(addresses_df.index))\n",
    "\n",
    "# Append rewards to the provided column, matching addresses between both sets\n",
    "def append_column_by_address(addresses_df, rewards_df, column, new_column_name=None):\n",
    "    def get_row_value_by_address(address):\n",
    "        matching_rows = rewards_df.loc[rewards_df['address'] == address]\n",
    "        total_matching_rows = len(matching_rows)\n",
    "        if total_matching_rows == 1:\n",
    "            return matching_rows.iloc[0][column]\n",
    "        elif total_matching_rows == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            raise Exception('Error appending column to final file', 'addresses are duplicated')\n",
    "    \n",
    "    result_df = addresses_df.copy()\n",
    "    if new_column_name is None:\n",
    "        new_column_name = column\n",
    "    print()\n",
    "    print('Appending \"%s\" column to final file' % new_column_name)\n",
    "    result_df.insert(len(result_df.columns), new_column_name, addresses_df.progress_apply(lambda x: get_row_value_by_address(x['address']), axis=1))\n",
    "    print()\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stakers\n",
    "\n",
    "There are two kinds of rewards for stakers:\n",
    "- Per user (divided equally among staking wallets)\n",
    "- Per stake amount (delivered proportionally to the amounts staked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Eligible Stakers: 945\n",
      "Staking reward per user: 291.005291005291\n",
      "                                        address       balance  \\\n",
      "0    0x0c14e2eecf6e8fc9042b91ced084ea0d7b9360de  6.469991e+14   \n",
      "1    0x07037fe3212eb56476d28fd0baaa4d1298cf571e  3.948147e+14   \n",
      "2    0x09363887a4096b142f3f6b58a7eed2f1a0ff7343  1.427428e+14   \n",
      "3    0x09ade54ba605dde33fd467ae0e05cdd64dafbc55  1.048798e+14   \n",
      "4    0x0181a709e165195bd67651bb5304b4cab6e0ada2  7.000000e+13   \n",
      "..                                          ...           ...   \n",
      "941  0x06230a286bd4ce2305640b4052fb8c8c64a9d2f2  1.000000e+11   \n",
      "942  0x0491e6133cc25a5debe5f44b782282ea64c2d8e5  1.000000e+11   \n",
      "943  0x001c46ba3a0d7f09302961f4811dc0521c0c3545  1.000000e+11   \n",
      "944  0x09a3741d22e8091a00d8041a92e7501bd069b517  1.000000e+11   \n",
      "945  0x0048a27710c2714b038186d055dd514688d8f707  1.000000e+11   \n",
      "\n",
      "     staker_reward_per_user  staker_reward_per_stake  \n",
      "0                291.005291             54438.750011  \n",
      "1                291.005291             33219.858812  \n",
      "2                291.005291             12010.433407  \n",
      "3                291.005291              8824.626206  \n",
      "4                291.005291              5889.826587  \n",
      "..                      ...                      ...  \n",
      "941              291.005291                 8.414038  \n",
      "942              291.005291                 8.414038  \n",
      "943              291.005291                 8.414038  \n",
      "944              291.005291                 8.414038  \n",
      "945              291.005291                 8.414038  \n",
      "\n",
      "[945 rows x 4 columns]\n",
      "\n",
      "Allocated reward (stakers, per user): 275000.0\n",
      "Calculated reward (stakers, per user): 275000.0\n",
      "\n",
      "Allocated reward (stakers, per stake): 275000.0\n",
      "Calculated reward (stakers, per stake): 275000.0\n",
      "\n",
      "Allocated reward (stakers, total): 550000.0\n",
      "Calculated reward (stakers, total): 550000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Total Eligible Stakers: %s' % len(eligible_addresses_stakers.index))\n",
    "\n",
    "rewards_stakers_df = eligible_addresses_stakers.copy()\n",
    "\n",
    "# Rewards per user\n",
    "\n",
    "half_staking_reward = TOTAL_STAKING_REWARD / 2\n",
    "\n",
    "reward_per_user = half_staking_reward / len(eligible_addresses_stakers)\n",
    "\n",
    "adjusted_reward_per_user = reward_per_user / CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "print('Staking reward per user: %s' % adjusted_reward_per_user)\n",
    "\n",
    "rewards_stakers_df.insert(len(rewards_stakers_df.columns), 'staker_reward_per_user', adjusted_reward_per_user)\n",
    "\n",
    "# Rewards per stake\n",
    "\n",
    "total_stake = eligible_addresses_stakers['balance'].sum()\n",
    "\n",
    "rewards_stakers_df['staker_reward_per_stake'] = rewards_stakers_df.apply(lambda x: calculate_percentage(half_staking_reward, np.double(x['balance']) / np.double(total_stake), DECIMALS_SDAO) / CONVERT_TO_FULL_BALANCE_SDAO, axis=1)\n",
    "\n",
    "print(rewards_stakers_df)\n",
    "\n",
    "adjusted_half_staker_reward = (half_staking_reward / CONVERT_TO_FULL_BALANCE_SDAO)\n",
    "\n",
    "calculated_staker_reward_per_user = np.sum(list(rewards_stakers_df['staker_reward_per_user']))\n",
    "\n",
    "calculated_staker_reward_per_stake = np.sum(list(rewards_stakers_df['staker_reward_per_stake']))\n",
    "\n",
    "rewards_stakers_df['balance'] = rewards_stakers_df['balance'] / CONVERT_TO_FULL_BALANCE_AGI\n",
    "\n",
    "print()\n",
    "print('Allocated reward (stakers, per user): %s' % adjusted_half_staker_reward)\n",
    "print('Calculated reward (stakers, per user): %s' % calculated_staker_reward_per_user)\n",
    "print()\n",
    "print('Allocated reward (stakers, per stake): %s' % adjusted_half_staker_reward)\n",
    "print('Calculated reward (stakers, per stake): %s' % calculated_staker_reward_per_stake)\n",
    "print()\n",
    "print('Allocated reward (stakers, total): %s' % (TOTAL_STAKING_REWARD / CONVERT_TO_FULL_BALANCE_SDAO))\n",
    "print('Calculated reward (stakers, total): %s' % (calculated_staker_reward_per_user + calculated_staker_reward_per_stake))\n",
    "print()\n",
    "\n",
    "per_user_error = np.ulonglong(calculated_staker_reward_per_user) != adjusted_half_staker_reward\n",
    "\n",
    "per_stake_error = np.ulonglong(calculated_staker_reward_per_stake) != adjusted_half_staker_reward\n",
    "\n",
    "total_error = (np.ulonglong(calculated_staker_reward_per_user) + np.ulonglong(calculated_staker_reward_per_stake)) != (adjusted_half_staker_reward * 2)\n",
    "\n",
    "if per_user_error or per_stake_error or total_error:\n",
    "    raise Exception('Error calculating rewards (stakers)', 'final reward sum does not match allocated reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the calculated rewards to final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▉                                                                                                                                                            | 566/15466 [00:00<00:05, 2829.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Appending \"staker_reward_per_user\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:05<00:00, 2798.70it/s]\n",
      "  4%|█████▉                                                                                                                                                            | 568/15466 [00:00<00:05, 2793.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appending \"staker_reward_per_stake\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:05<00:00, 2790.54it/s]\n",
      "  4%|█████▊                                                                                                                                                            | 555/15466 [00:00<00:05, 2761.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appending \"used_staker_balance\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:05<00:00, 2798.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                          address  staker_reward_per_user  \\\n",
      "0      0xbe0eb53f46cd790cd13851d5eff43d12404d33e8                0.000000   \n",
      "1      0xf977814e90da44bfa03b6295a0616a897441acec                0.000000   \n",
      "2      0xa1d8d972560c2f8144af871db508f0b0b10a3fbf                0.000000   \n",
      "3      0x19184ab45c40c2920b0e0e31413b9434abd243ed                0.000000   \n",
      "4      0x8699b0ffff9136df5fed0175baf4b65477378a3d                0.000000   \n",
      "...                                           ...                     ...   \n",
      "15461  0x00ea21e18daad781dfa97130e09c6e41c007dbbd              291.005291   \n",
      "15462  0x0a97a90e73af39c1819bafe9fc8846573d055ab1              291.005291   \n",
      "15463  0x0e5767bc10e638fa27475046e9edba581ed92dcf              291.005291   \n",
      "15464  0x0024b5903f0eb068e77f3e796bd2edea926c26e5              291.005291   \n",
      "15465  0x0b6010d0985ea30a99bd00a858724ed3896222fb              291.005291   \n",
      "\n",
      "       staker_reward_per_stake  used_staker_balance  \n",
      "0                     0.000000                  0.0  \n",
      "1                     0.000000                  0.0  \n",
      "2                     0.000000                  0.0  \n",
      "3                     0.000000                  0.0  \n",
      "4                     0.000000                  0.0  \n",
      "...                        ...                  ...  \n",
      "15461                 9.221786               1096.0  \n",
      "15462                 9.146059               1087.0  \n",
      "15463                 8.986193               1068.0  \n",
      "15464                 8.498178               1010.0  \n",
      "15465                 8.447694               1004.0  \n",
      "\n",
      "[15466 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "addresses_df = append_column_by_address(addresses_df, rewards_stakers_df, 'staker_reward_per_user')\n",
    "addresses_df = append_column_by_address(addresses_df, rewards_stakers_df, 'staker_reward_per_stake')\n",
    "addresses_df = append_column_by_address(addresses_df, rewards_stakers_df, 'balance', 'used_staker_balance')\n",
    "\n",
    "print(addresses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holders and LP\n",
    "\n",
    "Knowing the eligibility of the addresses, we can calculate the balances now using the following formula.\n",
    "\n",
    "With those premises in place, we can calculate the final reward for each user by using the following formula\n",
    "\n",
    "`Reward = total_reward * log10(1+user_balance) / SUM(log10(1+user_balance))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SUM(log10(1+user_balance)) as a constant variable\n",
    "\n",
    "holder_balances = list(eligible_addresses_holders['balance'])\n",
    "\n",
    "lp_balances = list(eligible_addresses_lp['balance'])\n",
    "\n",
    "balances_log10 = [np.log10(1 + (balance)) for balance in (holder_balances + lp_balances)]\n",
    "\n",
    "sum_balances_log10 = np.sum(balances_log10)\n",
    "\n",
    "# Define the function that calculates the reward for each user\n",
    "\n",
    "def calculate_reward(total_reward, user_balance_index):\n",
    "    user_balance_log10 = balances_log10[user_balance_index]\n",
    "    reward_percentage = np.double(user_balance_log10) / np.double(sum_balances_log10)\n",
    "    # Calculate reward and convert to final balance\n",
    "    return calculate_percentage(total_reward, reward_percentage, DECIMALS_AGI) / CONVERT_TO_FULL_BALANCE_SDAO\n",
    "\n",
    "# Calculate rewards and add the SDAO value as a column to the DateFrame\n",
    "\n",
    "holder_rewards = [calculate_reward(TOTAL_REWARD, index) for index, balance in enumerate(holder_balances)]\n",
    "\n",
    "lp_rewards = [calculate_reward(TOTAL_REWARD, len(holder_balances) + index) for index, balance in enumerate(lp_balances)]\n",
    "\n",
    "holder_rewards_df = eligible_addresses_holders.copy()\n",
    "\n",
    "lp_rewards_df = eligible_addresses_lp.copy()\n",
    "\n",
    "holder_rewards_df.insert(0, 'reward', holder_rewards)\n",
    "\n",
    "holder_rewards_df['balance'] = holder_rewards_df['balance'].apply(lambda x: x / CONVERT_TO_FULL_BALANCE_AGI)\n",
    "\n",
    "lp_rewards_df.insert(0, 'reward', lp_rewards)\n",
    "\n",
    "lp_rewards_df['balance'] = lp_rewards_df['balance'].apply(lambda x: x / CONVERT_TO_FULL_BALANCE_AGI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verify rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15509 15400 109\n",
      "Allocated reward (holders and LP): 825000.0\n",
      "Calculated reward (holders and LP): 825000.0\n"
     ]
    }
   ],
   "source": [
    "# Verify that the total amount of allocated reward matches the expected value\n",
    "\n",
    "calculated_reward = np.sum(list(holder_rewards_df['reward'])) + np.sum(list(lp_rewards_df['reward']))\n",
    "\n",
    "adjusted_total_reward = (TOTAL_REWARD / CONVERT_TO_FULL_BALANCE_SDAO)\n",
    "\n",
    "print(len(holder_balances + lp_balances), len(holder_balances), len(lp_balances))\n",
    "\n",
    "print('Allocated reward (holders and LP): %s' % adjusted_total_reward)\n",
    "print('Calculated reward (holders and LP): %s' % calculated_reward)\n",
    "\n",
    "if np.ulonglong(calculated_reward) != adjusted_total_reward:\n",
    "    raise Exception('Error calculating rewards', 'final reward sum does not match allocated reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add the calculated rewards to final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                              | 0/15466 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Appending \"holder_reward\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:20<00:00, 739.26it/s]\n",
      "  0%|▊                                                                                                                                                                   | 75/15466 [00:00<00:20, 742.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appending \"used_holder_balance\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:22<00:00, 702.16it/s]\n",
      "  2%|███▏                                                                                                                                                              | 302/15466 [00:00<00:05, 3020.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appending \"lp_reward\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:04<00:00, 3198.08it/s]\n",
      "  4%|██████▉                                                                                                                                                           | 660/15466 [00:00<00:04, 3295.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appending \"used_lp_balance\" column to final file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15466/15466 [00:04<00:00, 3286.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                          address  staker_reward_per_user  \\\n",
      "0      0xbe0eb53f46cd790cd13851d5eff43d12404d33e8                0.000000   \n",
      "1      0xf977814e90da44bfa03b6295a0616a897441acec                0.000000   \n",
      "2      0xa1d8d972560c2f8144af871db508f0b0b10a3fbf                0.000000   \n",
      "3      0x19184ab45c40c2920b0e0e31413b9434abd243ed                0.000000   \n",
      "4      0x8699b0ffff9136df5fed0175baf4b65477378a3d                0.000000   \n",
      "...                                           ...                     ...   \n",
      "15461  0x00ea21e18daad781dfa97130e09c6e41c007dbbd              291.005291   \n",
      "15462  0x0a97a90e73af39c1819bafe9fc8846573d055ab1              291.005291   \n",
      "15463  0x0e5767bc10e638fa27475046e9edba581ed92dcf              291.005291   \n",
      "15464  0x0024b5903f0eb068e77f3e796bd2edea926c26e5              291.005291   \n",
      "15465  0x0b6010d0985ea30a99bd00a858724ed3896222fb              291.005291   \n",
      "\n",
      "       staker_reward_per_stake  used_staker_balance  holder_reward  \\\n",
      "0                     0.000000                  0.0      73.108181   \n",
      "1                     0.000000                  0.0      71.932905   \n",
      "2                     0.000000                  0.0      64.525292   \n",
      "3                     0.000000                  0.0      68.678821   \n",
      "4                     0.000000                  0.0      68.586702   \n",
      "...                        ...                  ...            ...   \n",
      "15461                 9.221786               1096.0       0.000000   \n",
      "15462                 9.146059               1087.0       0.000000   \n",
      "15463                 8.986193               1068.0       0.000000   \n",
      "15464                 8.498178               1010.0       0.000000   \n",
      "15465                 8.447694               1004.0       0.000000   \n",
      "\n",
      "       used_holder_balance  lp_reward  used_lp_balance  \n",
      "0              141823360.0        0.0              0.0  \n",
      "1               78000000.0        0.0              0.0  \n",
      "2                1801089.0        0.0              0.0  \n",
      "3               14899506.0        0.0              0.0  \n",
      "4               14217393.0        0.0              0.0  \n",
      "...                    ...        ...              ...  \n",
      "15461                  0.0        0.0              0.0  \n",
      "15462                  0.0        0.0              0.0  \n",
      "15463                  0.0        0.0              0.0  \n",
      "15464                  0.0        0.0              0.0  \n",
      "15465                  0.0        0.0              0.0  \n",
      "\n",
      "[15466 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Add rewards to final data frame\n",
    "\n",
    "addresses_df = append_column_by_address(addresses_df, holder_rewards_df, 'reward', 'holder_reward')\n",
    "addresses_df = append_column_by_address(addresses_df, holder_rewards_df, 'balance', 'used_holder_balance')\n",
    "addresses_df = append_column_by_address(addresses_df, lp_rewards_df, 'reward', 'lp_reward')\n",
    "addresses_df = append_column_by_address(addresses_df, lp_rewards_df, 'balance', 'used_lp_balance')\n",
    "\n",
    "print(addresses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding unclaimed balances\n",
    "\n",
    "The missing step would be sum all the unclaimed amount from previous airdrops, for this example that's not possible with the data at hand though."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e11c16bd8665eb0b93b5a4e36de9de775b152bd48248748b339502fe1d55318"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
